---
title: "Reading Data From The Web"
author: "Sarahy Martinez"
date: "2024-10-09"
output: github_document
---


```{r, eval=FALSE}
library(tidyverse)
library(rvest)   #new packages, tidyverse adjacent 
library(httr)

#format for your plots and graphs

knitr:: opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Scrape a table

First, let’s make sure we can load the data from the web.


I want the first page from [this page] http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm

```{r, eval= FALSE}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_html = read_html(url)
# name of dataframe = read_html 

drug_use_html  #when we print its a bit of a mess but dont care, just happy that we have an html doc
```

Doesn’t look like much, but we’re there. Rather than trying to grab something using a CSS selector, let’s try our luck extracting the tables from the HTML.

Extract the tables that you want, you can do CSS selector but css tag for html is common enough that he is just going to guess that what you're looking for is a table.

```{r, eval=FALSE}
# option 1 
drug_use_html %>% 
  html_nodes(css = "table")    #extracts html nodes with a particular css tag, have table but not good bc dont have tibble

#option 2
drug_use_html %>% 
  html_table()


```

This has extracted all of the tables on the original page; that’s why we have a list with 15 elements. (We haven’t really talked about lists yet, but for now you can think of them as a general collection of objects in R. As we proceed, syntax for extracting individual elements from a list will become clear, and we’ll talk lots about lists in list columns.)

We’re only focused on the first table for now, so let’s get the contents from the first list element.


```{r, eval=FALSE}
#extracting the tables and focusing on one 

table_marj = 
  drug_use_html %>% 
  html_table()  %>%
  first() 

print(table_marj)

# other example but doesnt work 

drug_use_html %>% 
  html_nodes(css = "table") %>% 
  first() %>%   #still formatted html and we want to format as text so we will parce html to strip html and  
  html_table  #get wanted pieces by using the html_table function 

```

In table here if you look at it you’ll notice a problem: the “note” at the bottom of the table appears in every column in the first row. We need to remove that…

```{r, eval=FALSE}
table_marj = 
  drug_use_html  %>%
  html_table()  %>%
  first() %>% 
  slice(-1) #removes the first 

table_marj
#notice that data is stored as characters also some superscripts, subscripts, data not necessarily tidy, very least we pulled data from the internet

# other but doesnt run
drug_use_html %>% 
  html_nodes(css= "table") %>% 
  first() %>% 
  html_table() %>% 
  slice(-1) %>% 
  as_tibble()
  
```

Now lets shift and try to get a non-table collection of data from the website 

Suppose we’d like to scrape the data about the Star Wars Movies from the IMDB page. The first step is the same as before – we need to get the HTML.

## Star Wars Movie Info

I want the data from [here](https://www.imdb.com/list/ls070150896/)

```{r, eval=FALSE}
swm_html = 
  read_html("https://www.imdb.com/list/ls070150896/")

#can also do this 

url = "https://www.imdb.com/list/ls070150896/"

swm_htmls = read_html(url)

```

The information isn’t stored in a handy table, so we’re going to isolate the CSS selector for elements we care about. A bit of clicking around gets me something like below.

Grab elements that we want:
- before said give me the tables but we dont know the css tag imdb for movie titles. We willfocus on titles and make a vector. Get the star wars html and extract 

```{r, eval=FALSE}
title_vectors_ex_one = 
  swm_html %>% 
  html_nodes(css=".lister-item-header a") %>% 
  html_text()#because its not a table with info we dont know which css function, so use selector gadget page

gross_rev_vec = 
  swm_html %>% 
  html_nodes(css=".text-small:nth-child(7) span:nth-child(5)") %>% 
  html_text()

runtime_vec= 
  swm_html %>% 
  html_nodes(css=".runtime") %>% 
  html_text()

#putting it all together 

swm_df_video= 
  tibble(
    tibble= title_vec,
    gross_rev_vec = gross_rev_vec,
    runtime_vec = runtime_vec
  )
  

```


```{r second form of code working, eval=FALSE}
title_vec = 
  swm_html %>% 
  html_elements(".ipc-title-link-wrapper .ipc-title__text") %>% 
  html_text()

metascore_vec = 
  swm_html %>% 
  html_elements(".metacritic-score-box") %>% 
  html_text()

runtime_vec = 
  swm_html %>% 
  html_elements(".dli-title-metadata-item:nth-child(2)") %>% #knowing how long the movies are, find elements associated                                                                #with runtime pull it out and 
  html_text()   #convert to text

swm_df = 
  tibble(
    title = title_vec,
    score = metascore_vec,
    runtime = runtime_vec)
```

We need to extract some bit of css for the movie title 
on page, click selector gadget and scroll through will highlight boxes of content and paths. Click on smallest box that includes what we care about. unclick things that show up unrelated that you want. Then selector will tell you the package to use.video 

```{r}

```








